{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import glasbey\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path\n",
    "import distro\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables/iclr26v1\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs01/berens/user/rgonzalesmarquez'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL FIX TO PATH ISSUE FROM VSCODE\n",
    "nb_path = Path(\"phd/iclr-dataset/scripts\")\n",
    "assert nb_path.exists(), \"The path does not exist\"\n",
    "\n",
    "variables_path = (nb_path / variables_path).resolve(strict=True)\n",
    "figures_path = (nb_path / figures_path).resolve(strict=True)\n",
    "data_path = (nb_path / data_path).resolve(strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/phd/iclr-dataset/results/variables/iclr26v1\n"
     ]
    }
   ],
   "source": [
    "print(variables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use((nb_path / Path(\"matplotlib_style.txt\")).resolve(strict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rita Gonz치lez-M치rquez\n",
      "\n",
      "Last updated: 2025-11-17 10:38:44CET\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.4\n",
      "IPython version      : 8.31.0\n",
      "\n",
      "transformers: 4.45.2\n",
      "openTSNE    : 1.0.2\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 4.18.0-553.el8_10.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: rgonzalesmarquez_GPU0-llm_gber7\n",
      "\n",
      "pandas         : 2.2.3\n",
      "seaborn        : 0.13.2\n",
      "distro         : 1.9.0\n",
      "glasbey        : 0.2.1\n",
      "numpy          : 1.26.4\n",
      "jupyter_black  : 0.4.0\n",
      "memory_profiler: 0.61.0\n",
      "matplotlib     : 3.9.2\n",
      "\n",
      "Watermark: 2.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a 'Rita Gonz치lez-M치rquez' -t -d -tz -u -v -iv -w -m -h -p transformers,openTSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "ICLR new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 205 ms, sys: 73.9 ms, total: 278 ms\n",
      "Wall time: 280 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iclr = pd.read_parquet(\n",
    "    data_path / \"iclr26v1.parquet\",\n",
    "    engine=\"fastparquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55901</th>\n",
       "      <td>2026</td>\n",
       "      <td>zz3El6hqbs</td>\n",
       "      <td>Learning activation functions with PCA on a se...</td>\n",
       "      <td>This work explores a novel approach to learnin...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[deep neural networks, activation function lea...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55902</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzJTo7ujql</td>\n",
       "      <td>Phased DMD: Few-step Distribution Matching Dis...</td>\n",
       "      <td>Distribution Matching Distillation (DMD) disti...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[diffusion models, distribution matching, dist...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55903</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzTDulLys0</td>\n",
       "      <td>vAttention: Verified Sparse Attention via Samp...</td>\n",
       "      <td>State-of-the-art sparse attention methods for ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[sparse attention]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55904</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzTQISAGUp</td>\n",
       "      <td>Polychromic Objectives for Reinforcement Learning</td>\n",
       "      <td>Reinforcement learning fine-tuning (RLFT) is a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[reinforcement learning, exploration]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55905</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzo3Sy3NSX</td>\n",
       "      <td>Your Language Model Secretly Contains Personal...</td>\n",
       "      <td>Large Language Models (LLMs) demonstrate remar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[large language models, persona modeling]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year          id                                              title  \\\n",
       "55901  2026  zz3El6hqbs  Learning activation functions with PCA on a se...   \n",
       "55902  2026  zzJTo7ujql  Phased DMD: Few-step Distribution Matching Dis...   \n",
       "55903  2026  zzTDulLys0  vAttention: Verified Sparse Attention via Samp...   \n",
       "55904  2026  zzTQISAGUp  Polychromic Objectives for Reinforcement Learning   \n",
       "55905  2026  zzo3Sy3NSX  Your Language Model Secretly Contains Personal...   \n",
       "\n",
       "                                                abstract authors author_ids  \\\n",
       "55901  This work explores a novel approach to learnin...                      \n",
       "55902  Distribution Matching Distillation (DMD) disti...                      \n",
       "55903  State-of-the-art sparse attention methods for ...                      \n",
       "55904  Reinforcement learning fine-tuning (RLFT) is a...                      \n",
       "55905  Large Language Models (LLMs) demonstrate remar...                      \n",
       "\n",
       "      decision scores                                           keywords  \\\n",
       "55901              []  [deep neural networks, activation function lea...   \n",
       "55902              []  [diffusion models, distribution matching, dist...   \n",
       "55903              []                                 [sparse attention]   \n",
       "55904              []              [reinforcement learning, exploration]   \n",
       "55905              []          [large language models, persona modeling]   \n",
       "\n",
       "      labels  \n",
       "55901   None  \n",
       "55902   None  \n",
       "55903   None  \n",
       "55904   None  \n",
       "55905   None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr[\"keywords\"] = iclr[\"keywords\"].apply(lambda x: [s.lower() for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55901</th>\n",
       "      <td>2026</td>\n",
       "      <td>zz3El6hqbs</td>\n",
       "      <td>Learning activation functions with PCA on a se...</td>\n",
       "      <td>This work explores a novel approach to learnin...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[deep neural networks, activation function lea...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55902</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzJTo7ujql</td>\n",
       "      <td>Phased DMD: Few-step Distribution Matching Dis...</td>\n",
       "      <td>Distribution Matching Distillation (DMD) disti...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[diffusion models, distribution matching, dist...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55903</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzTDulLys0</td>\n",
       "      <td>vAttention: Verified Sparse Attention via Samp...</td>\n",
       "      <td>State-of-the-art sparse attention methods for ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[sparse attention]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55904</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzTQISAGUp</td>\n",
       "      <td>Polychromic Objectives for Reinforcement Learning</td>\n",
       "      <td>Reinforcement learning fine-tuning (RLFT) is a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[reinforcement learning, exploration]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55905</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzo3Sy3NSX</td>\n",
       "      <td>Your Language Model Secretly Contains Personal...</td>\n",
       "      <td>Large Language Models (LLMs) demonstrate remar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[large language models, persona modeling]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year          id                                              title  \\\n",
       "55901  2026  zz3El6hqbs  Learning activation functions with PCA on a se...   \n",
       "55902  2026  zzJTo7ujql  Phased DMD: Few-step Distribution Matching Dis...   \n",
       "55903  2026  zzTDulLys0  vAttention: Verified Sparse Attention via Samp...   \n",
       "55904  2026  zzTQISAGUp  Polychromic Objectives for Reinforcement Learning   \n",
       "55905  2026  zzo3Sy3NSX  Your Language Model Secretly Contains Personal...   \n",
       "\n",
       "                                                abstract authors author_ids  \\\n",
       "55901  This work explores a novel approach to learnin...                      \n",
       "55902  Distribution Matching Distillation (DMD) disti...                      \n",
       "55903  State-of-the-art sparse attention methods for ...                      \n",
       "55904  Reinforcement learning fine-tuning (RLFT) is a...                      \n",
       "55905  Large Language Models (LLMs) demonstrate remar...                      \n",
       "\n",
       "      decision scores                                           keywords  \\\n",
       "55901              []  [deep neural networks, activation function lea...   \n",
       "55902              []  [diffusion models, distribution matching, dist...   \n",
       "55903              []                                 [sparse attention]   \n",
       "55904              []              [reinforcement learning, exploration]   \n",
       "55905              []          [large language models, persona modeling]   \n",
       "\n",
       "      labels  \n",
       "55901   None  \n",
       "55902   None  \n",
       "55903   None  \n",
       "55904   None  \n",
       "55905   None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55906, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign new labels\n",
    "Labels are the same as for the 25v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists of keywords and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keyword_to_label = {\n",
    "    ###### ADVERSARIAL\n",
    "    \"adversarial\": \"adversarial\",\n",
    "    \"adversarial attack\": \"adversarial\",\n",
    "    \"adversarial attacks\": \"adversarial\",\n",
    "    \"adversarial defense\": \"adversarial\",\n",
    "    \"adversarial examples\": \"adversarial\",\n",
    "    \"adversarial example\": \"adversarial\",  # NEW 2025\n",
    "    \"adversarial learning\": \"adversarial\",\n",
    "    \"adversarial machine learning\": \"adversarial\",\n",
    "    \"adversarial robustness\": \"adversarial\",\n",
    "    \"adversarial training\": \"adversarial\",\n",
    "    ###### TRANSFORMERS\n",
    "    \"attention\": \"transformers\",\n",
    "    \"attention mechanism\": \"transformers\",\n",
    "    \"transformer\": \"transformers\",\n",
    "    \"transformers\": \"transformers\",\n",
    "    \"self-attention\": \"transformers\",\n",
    "    ###### AUTOENCODERS\n",
    "    \"autoencoder\": \"autoencoders\",\n",
    "    \"autoencoders\": \"autoencoders\",\n",
    "    \"vae\": \"autoencoders\",\n",
    "    \"vaes\": \"autoencoders\",  # NEW 2025\n",
    "    \"variational autoencoder\": \"autoencoders\",\n",
    "    \"variational autoencoders\": \"autoencoders\",\n",
    "    ######\n",
    "    \"anomaly detection\": \"anomaly detection\",\n",
    "    ###### CAUSALITY\n",
    "    \"causal discovery\": \"causality\",\n",
    "    \"causal inference\": \"causality\",\n",
    "    \"causality\": \"causality\",\n",
    "    ######\n",
    "    \"clustering\": \"clustering\",\n",
    "    ###### COMPRESSION\n",
    "    \"compression\": \"compression\",\n",
    "    \"model compression\": \"compression\",\n",
    "    ######\n",
    "    \"object detection\": \"object detection\",\n",
    "    \"semantic segmentation\": \"object detection\",  # NEW 2025\n",
    "    # ######  -- MOVED TO SSL IN 2025\n",
    "    # \"contrastive learning\": \"contrastive learning\",\n",
    "    ###### CNNs\n",
    "    \"convolutional neural network\": \"CNNs\",\n",
    "    \"convolutional neural networks\": \"CNNs\",\n",
    "    \"cnn\": \"CNNs\",\n",
    "    \"cnns\": \"CNNs\",  # NEW 2025\n",
    "    ###### DIFFUSION MODELS\n",
    "    \"diffusion\": \"diffusion models\",\n",
    "    \"diffusion model\": \"diffusion models\",\n",
    "    \"diffusion models\": \"diffusion models\",\n",
    "    ###### EXPLAINABILITY\n",
    "    \"explainability\": \"explainability\",\n",
    "    \"explainable ai\": \"explainability\",\n",
    "    ######\n",
    "    \"interpretability\": \"interpretability\",\n",
    "    ######\n",
    "    \"fairness\": \"fairness\",\n",
    "    ######\n",
    "    \"federated learning\": \"federated learning\",\n",
    "    ###### GANs\n",
    "    \"generative adversarial network\": \"GANs\",\n",
    "    \"generative adversarial networks\": \"GANs\",\n",
    "    \"gan\": \"GANs\",\n",
    "    \"gans\": \"GANs\",\n",
    "    ###### GRAPHS\n",
    "    \"graph\": \"graphs\",\n",
    "    \"graphs\": \"graphs\",  # NEW 2025\n",
    "    \"graph neural network\": \"graphs\",\n",
    "    \"graph neural networks\": \"graphs\",\n",
    "    \"graph representation learning\": \"graphs\",\n",
    "    \"gnn\": \"graphs\",  # NEW 2025\n",
    "    \"gnns\": \"graphs\",\n",
    "    \"node classification\": \"graphs\",\n",
    "    ###### LLMs\n",
    "    \"llm\": \"LLMs\",\n",
    "    \"large language model\": \"LLMs\",\n",
    "    \"large language models\": \"LLMs\",\n",
    "    \"prompting\": \"LLMs\",\n",
    "    \"bert\": \"LLMs\",  # NEW 2025\n",
    "    \"llms\": \"LLMs\",  # NEW 2025\n",
    "    \"text generation\": \"LLMs\",  # NEW 2025\n",
    "    ######\n",
    "    \"knowledge distillation\": \"knowledge distillation\",\n",
    "    ###### LANGUAGE MODELS\n",
    "    \"natural language processing\": \"language models\",\n",
    "    \"nlp\": \"language models\",\n",
    "    \"language model\": \"language models\",\n",
    "    \"language models\": \"language models\",\n",
    "    \"language modeling\": \"language models\",\n",
    "    \"machine translation\": \"language models\",\n",
    "    \"question answering\": \"language models\",\n",
    "    \"reasoning\": \"language models\",\n",
    "    ###### META LEARNING\n",
    "    \"meta learning\": \"meta learning\",\n",
    "    \"meta-learning\": \"meta learning\",\n",
    "    ###### PRUNING\n",
    "    \"network pruning\": \"pruning\",\n",
    "    \"pruning\": \"pruning\",\n",
    "    ######\n",
    "    \"neural architecture search\": \"neural architecture search\",\n",
    "    ######\n",
    "    \"optimal transport\": \"optimal transport\",\n",
    "    ###### OPTIMIZATION\n",
    "    \"stochastic gradient descent\": \"optimization\",\n",
    "    \"stochastic optimization\": \"optimization\",\n",
    "    \"sgd\": \"optimization\",\n",
    "    \"optimization\": \"optimization\",\n",
    "    \"non-convex optimization\": \"optimization\",\n",
    "    \"convex optimization\": \"optimization\",\n",
    "    \"gradient descent\": \"optimization\",\n",
    "    \"combinatorial optimization\": \"optimization\",\n",
    "    \"bayesian optimization\": \"optimization\",\n",
    "    ###### OUT-OF-DISTRIBUTION\n",
    "    \"out-of-distribution\": \"out-of-distribution\",\n",
    "    \"out-of-distribution detection\": \"out-of-distribution\",\n",
    "    \"out-of-distribution generalization\": \"out-of-distribution\",\n",
    "    \"distribution shift\": \"out-of-distribution\",\n",
    "    ###### PRIVACY\n",
    "    \"differential privacy\": \"privacy\",\n",
    "    \"privacy\": \"privacy\",\n",
    "    ###### RNNs\n",
    "    \"rnn\": \"RNNs\",\n",
    "    \"rnns\": \"RNNs\",  # NEW 2025\n",
    "    \"recurrent neural network\": \"RNNs\",\n",
    "    \"recurrent neural networks\": \"RNNs\",\n",
    "    \"lstm\": \"RNNs\",\n",
    "    ###### REINFORCEMENT LEARNING\n",
    "    \"reinforcement learning\": \"RL\",\n",
    "    \"deep reinforcement learning\": \"RL\",\n",
    "    ######\n",
    "    \"active learning\": \"active learning\",\n",
    "    ######\n",
    "    \"model-based reinforcement learning\": \"model-based RL\",\n",
    "    ######\n",
    "    \"multi-agent reinforcement learning\": \"multi-agent RL\",\n",
    "    \"multi-agent\": \"multi-agent RL\",  # NEW 2025\n",
    "    ######\n",
    "    \"multi-task learning\": \"multi-task learning\",\n",
    "    ######\n",
    "    \"imitation learning\": \"imitation learning\",\n",
    "    ###### OFFLINE RL\n",
    "    \"offline reinforcement learning\": \"offline RL\",\n",
    "    \"offline rl\": \"offline RL\",\n",
    "    ###### CONTINUAL LEARNING\n",
    "    \"continual learning\": \"continual learning\",\n",
    "    \"lifelong learning\": \"continual learning\",\n",
    "    ######\n",
    "    \"in-context learning\": \"in-context learning\",\n",
    "    ######\n",
    "    \"few-shot learning\": \"few-shot learning\",\n",
    "    ######\n",
    "    \"robustness\": \"robustness\",\n",
    "    ###### SELF-SUPERVISED LEARNING\n",
    "    \"self-supervised learning\": \"self-supervised learning\",\n",
    "    \"contrastive learning\": \"self-supervised learning\",\n",
    "    ######\n",
    "    \"semi-supervised learning\": \"semi-supervised learning\",\n",
    "    ###### TIME SERIES\n",
    "    \"time series\": \"time series\",\n",
    "    \"time series forecasting\": \"time series\",\n",
    "    ###### TRANSFER LEARNING\n",
    "    \"transfer learning\": \"transfer learning\",\n",
    "    \"domain adaptation\": \"transfer learning\",\n",
    "    \"domain generalization\": \"transfer learning\",\n",
    "    ###### ViTs\n",
    "    \"vision transformer\": \"ViTs\",\n",
    "    \"vision transformers\": \"ViTs\",\n",
    "    ###### VISION-LANGUAGE MODELS\n",
    "    \"vision-language models\": \"vision-language models\",\n",
    "    \"vision-language model\": \"vision-language models\",  # NEW 2025\n",
    "    \"clip\": \"vision-language models\",\n",
    "    ###### ---------------------------- NEW 2025 --------------------------------\n",
    "    #### SAFETY\n",
    "    \"ai safety\": \"safety\",\n",
    "    \"safety\": \"safety\",\n",
    "    #### ALIGNMENT\n",
    "    \"alignment\": \"alignment\",\n",
    "    \"rlhf\": \"alignment\",\n",
    "    #####\n",
    "    \"autonomous driving\": \"autonomous driving\",\n",
    "    #### CODE GENERATION\n",
    "    \"code generation\": \"code generation\",\n",
    "    \"program synthesis\": \"code generation\",\n",
    "    #### KNOWLEDGE GRAPHS\n",
    "    \"knowledge graph\": \"knowledge graphs\",\n",
    "    \"knowledge graphs\": \"knowledge graphs\",\n",
    "    # ####\n",
    "    \"neuroscience\": \"neuroscience\",\n",
    "    ###### ---------------------------- NEW 2026 --------------------------------\n",
    "    #### 3D SCENES\n",
    "    \"3d reconstruction\": \"3D scenes\",\n",
    "    \"novel view synthesis\": \"3D scenes\",\n",
    "    \"nerf\": \"3D scenes\",\n",
    "    \"gaussian splatting\": \"3D scenes\",\n",
    "    #### SPEECH\n",
    "    \"speech synthesis\": \"speech\",\n",
    "    \"text-to-speech\": \"speech\",\n",
    "    \"speech recognition\": \"speech\",\n",
    "    #### MOLECULES\n",
    "    \"drug discovery\": \"molecules\",\n",
    "    \"molecule generation\": \"molecules\",\n",
    "    #### PDES\n",
    "    \"partial differential equations\": \"PDEs\",\n",
    "    \"dynamical systems\": \"PDEs\",\n",
    "    \"pdes\": \"PDEs\",\n",
    "    \"pde\": \"PDEs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# keywords:  147\n",
      "# labels:  54\n"
     ]
    }
   ],
   "source": [
    "print(\"# keywords: \", len(np.unique(list(dict_keyword_to_label.keys()))))\n",
    "print(\"# labels: \", len(np.unique(list(dict_keyword_to_label.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_keywords, counts = np.unique(\n",
    "    np.hstack(iclr.keywords), return_counts=True\n",
    ")\n",
    "\n",
    "n = 200\n",
    "unique_keywords_sorted = unique_keywords[np.flip(np.argsort(counts))]\n",
    "counts_sorted = np.flip(np.sort(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keywords_frequencies = dict(zip(unique_keywords_sorted, counts_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('adversarial', 75),\n",
       "  ('adversarial attack', 225),\n",
       "  ('adversarial attacks', 213),\n",
       "  ('adversarial defense', 79),\n",
       "  ('adversarial examples', 220),\n",
       "  ('adversarial example', 35),\n",
       "  ('adversarial learning', 119),\n",
       "  ('adversarial machine learning', 78),\n",
       "  ('adversarial robustness', 390),\n",
       "  ('adversarial training', 291)],\n",
       " [('attention', 333),\n",
       "  ('attention mechanism', 104),\n",
       "  ('transformer', 674),\n",
       "  ('transformers', 604),\n",
       "  ('self-attention', 118)],\n",
       " [('autoencoder', 103),\n",
       "  ('autoencoders', 71),\n",
       "  ('vae', 104),\n",
       "  ('vaes', 10),\n",
       "  ('variational autoencoder', 130),\n",
       "  ('variational autoencoders', 99)],\n",
       " [('anomaly detection', 237)],\n",
       " [('causal discovery', 142), ('causal inference', 248), ('causality', 166)],\n",
       " [('clustering', 225)],\n",
       " [('compression', 231), ('model compression', 269)],\n",
       " [('object detection', 208), ('semantic segmentation', 147)],\n",
       " [('convolutional neural network', 86),\n",
       "  ('convolutional neural networks', 153),\n",
       "  ('cnn', 118),\n",
       "  ('cnns', 29)],\n",
       " [('diffusion', 347), ('diffusion model', 717), ('diffusion models', 1153)],\n",
       " [('explainability', 269), ('explainable ai', 222)],\n",
       " [('interpretability', 902)],\n",
       " [('fairness', 353)],\n",
       " [('federated learning', 889)],\n",
       " [('generative adversarial network', 79),\n",
       "  ('generative adversarial networks', 202),\n",
       "  ('gan', 180),\n",
       "  ('gans', 101)],\n",
       " [('graph', 96),\n",
       "  ('graphs', 60),\n",
       "  ('graph neural network', 414),\n",
       "  ('graph neural networks', 992),\n",
       "  ('graph representation learning', 142),\n",
       "  ('gnn', 109),\n",
       "  ('gnns', 41),\n",
       "  ('node classification', 100)],\n",
       " [('llm', 1234),\n",
       "  ('large language model', 1402),\n",
       "  ('large language models', 2852),\n",
       "  ('prompting', 78),\n",
       "  ('bert', 94),\n",
       "  ('llms', 554),\n",
       "  ('text generation', 85)],\n",
       " [('knowledge distillation', 437)],\n",
       " [('natural language processing', 550),\n",
       "  ('nlp', 258),\n",
       "  ('language model', 227),\n",
       "  ('language models', 466),\n",
       "  ('language modeling', 139),\n",
       "  ('machine translation', 117),\n",
       "  ('question answering', 125),\n",
       "  ('reasoning', 663)],\n",
       " [('meta learning', 172), ('meta-learning', 384)],\n",
       " [('network pruning', 55), ('pruning', 237)],\n",
       " [('neural architecture search', 223)],\n",
       " [('optimal transport', 333)],\n",
       " [('stochastic gradient descent', 98),\n",
       "  ('stochastic optimization', 126),\n",
       "  ('sgd', 113),\n",
       "  ('optimization', 740),\n",
       "  ('non-convex optimization', 110),\n",
       "  ('convex optimization', 111),\n",
       "  ('gradient descent', 134),\n",
       "  ('combinatorial optimization', 161),\n",
       "  ('bayesian optimization', 148)],\n",
       " [('out-of-distribution', 93),\n",
       "  ('out-of-distribution detection', 168),\n",
       "  ('out-of-distribution generalization', 107),\n",
       "  ('distribution shift', 165)],\n",
       " [('differential privacy', 301), ('privacy', 243)],\n",
       " [('rnn', 93),\n",
       "  ('rnns', 35),\n",
       "  ('recurrent neural network', 59),\n",
       "  ('recurrent neural networks', 148),\n",
       "  ('lstm', 80)],\n",
       " [('reinforcement learning', 3370), ('deep reinforcement learning', 402)],\n",
       " [('active learning', 227)],\n",
       " [('model-based reinforcement learning', 160)],\n",
       " [('multi-agent reinforcement learning', 293), ('multi-agent', 129)],\n",
       " [('multi-task learning', 252)],\n",
       " [('imitation learning', 314)],\n",
       " [('offline reinforcement learning', 286), ('offline rl', 103)],\n",
       " [('continual learning', 663), ('lifelong learning', 125)],\n",
       " [('in-context learning', 408)],\n",
       " [('few-shot learning', 309)],\n",
       " [('robustness', 721)],\n",
       " [('self-supervised learning', 761), ('contrastive learning', 618)],\n",
       " [('semi-supervised learning', 327)],\n",
       " [('time series', 309), ('time series forecasting', 244)],\n",
       " [('transfer learning', 570),\n",
       "  ('domain adaptation', 297),\n",
       "  ('domain generalization', 190)],\n",
       " [('vision transformer', 153), ('vision transformers', 107)],\n",
       " [('vision-language models', 307),\n",
       "  ('vision-language model', 147),\n",
       "  ('clip', 187)],\n",
       " [('ai safety', 244), ('safety', 286)],\n",
       " [('alignment', 389), ('rlhf', 191)],\n",
       " [('autonomous driving', 207)],\n",
       " [('code generation', 203), ('program synthesis', 91)],\n",
       " [('knowledge graph', 117), ('knowledge graphs', 77)],\n",
       " [('neuroscience', 171)],\n",
       " [('3d reconstruction', 121),\n",
       "  ('novel view synthesis', 99),\n",
       "  ('nerf', 52),\n",
       "  ('gaussian splatting', 106)],\n",
       " [('speech synthesis', 42),\n",
       "  ('text-to-speech', 45),\n",
       "  ('speech recognition', 54)],\n",
       " [('drug discovery', 91), ('molecule generation', 56)],\n",
       " [('partial differential equations', 95),\n",
       "  ('dynamical systems', 141),\n",
       "  ('pdes', 45),\n",
       "  ('pde', 44)]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_keywords = [\n",
    "    dict_keywords_frequencies[key] for key in dict_keyword_to_label.keys()\n",
    "]\n",
    "\n",
    "list_to_group = list(\n",
    "    zip(\n",
    "        dict_keyword_to_label.values(),\n",
    "        dict_keyword_to_label.keys(),\n",
    "        freqs_keywords,\n",
    "    )\n",
    ")\n",
    "key_func = lambda x: x[0]\n",
    "\n",
    "final_keywords_groups = []\n",
    "for key, group in itertools.groupby(list_to_group, key_func):\n",
    "    final_keywords_groups.append([elem[1:] for elem in group])\n",
    "\n",
    "final_keywords_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend color palette\n",
    "DELETE THIS SECTION IN V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\n",
    "    \"/gpfs01/berens/user/rgonzalesmarquez/phd/iclr-dataset/results/variables/iclr25v2/dict_label_to_color.pkl\",\n",
    "    \"rb\",\n",
    ")\n",
    "dict_label_to_color = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# labels without 'unlabeled':  54\n",
      "# colors with 'unlabeled':  51\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 7425x135 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "n_labels = len(np.unique(list(dict_keyword_to_label.values())))\n",
    "print(\"# labels without 'unlabeled': \", n_labels)\n",
    "n_colors = len(list(dict_label_to_color.values()))\n",
    "print(\"# colors with 'unlabeled': \", n_colors)\n",
    "\n",
    "if (n_labels + 1) != n_colors:\n",
    "\n",
    "    old_palette = list(dict_label_to_color.values())\n",
    "\n",
    "    palette = glasbey.extend_palette(\n",
    "        old_palette,\n",
    "        palette_size=n_labels + 1,  # +1 : unlabeled\n",
    "        lightness_bounds=(20, 75),\n",
    "        chroma_bounds=(50, 90),\n",
    "        hue_bounds=(220, 90),\n",
    "    )\n",
    "    sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molecules #5161b2\n",
      "speech #598aff\n",
      "3D scenes #c631ff\n",
      "PDEs #ce4900\n"
     ]
    }
   ],
   "source": [
    "dict_label_to_color_extended = dict_label_to_color.copy()\n",
    "\n",
    "for i, elem in enumerate(\n",
    "    set(dict_keyword_to_label.values()).difference(\n",
    "        set(dict_label_to_color.keys())\n",
    "    )\n",
    "):\n",
    "    print(elem, palette[n_colors + i])\n",
    "    dict_label_to_color_extended[elem] = palette[n_colors + i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(variables_path / \"dict_label_to_color.pkl\", \"wb\")\n",
    "pickle.dump(dict_label_to_color_extended, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def assign_labels_and_colors(\n",
    "    data, keywords_and_freqs, dict_keyword_to_label, dict_color_legend=None\n",
    "):\n",
    "    \"\"\"Assign labels and colors from list with lists of keywords.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: list of lists, len (n_samples)\n",
    "        List with lists of keywords for every paper.\n",
    "    keywords_and_freqs: list of lists, len (n_labels)\n",
    "        List of keywords groups. Contains all keywords and frequencies, with sublists of subgroups of keywords.\n",
    "    dict_keyword_to_label: dict\n",
    "        Dictionary assigning to each keyword its label (e.g. to all keywords in same subgroup same label).\n",
    "    dict_color_legend: dict, len (n_labels)\n",
    "        Dictionary assigning to each label a color.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels: array, shape (n_samples,)\n",
    "        Label for each paper.\n",
    "    colors: array, shape (n_samples,)\n",
    "        Color for each paper.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare dict_freqs\n",
    "    dict_freqs = dict(list(itertools.chain.from_iterable(keywords_and_freqs)))\n",
    "    dict_freqs[\"unlabeled\"] = (\n",
    "        1e9  # assign very large value to unlabeled for argmax\n",
    "    )\n",
    "\n",
    "    # clean empty lists of keywords from the data\n",
    "    data_without_empty = [\n",
    "        [\"unlabeled\"] if elem == [] else elem for elem in data\n",
    "    ]\n",
    "\n",
    "    # choose keywords for each paper\n",
    "    chosen_keywords = []\n",
    "    for list_keywords in data_without_empty:\n",
    "        list_keywords_filtered = [\n",
    "            elem if elem in set(dict_freqs.keys()) else \"unlabeled\"\n",
    "            for elem in list_keywords\n",
    "        ]\n",
    "\n",
    "        freqs = np.vectorize(dict_freqs.get)(list_keywords_filtered)\n",
    "\n",
    "        chosen_keyword = list_keywords_filtered[np.argmin(freqs)]\n",
    "        chosen_keywords.append(chosen_keyword)\n",
    "\n",
    "    chosen_keywords = np.array(chosen_keywords)\n",
    "\n",
    "    # map chosen keywords to labels\n",
    "    dict_keyword_to_label[\"unlabeled\"] = \"unlabeled\"\n",
    "    labels = np.vectorize(dict_keyword_to_label.get)(chosen_keywords)\n",
    "\n",
    "    if dict_color_legend:\n",
    "        # colors\n",
    "        colors = np.vectorize(dict_color_legend.get)(labels)\n",
    "\n",
    "    else:\n",
    "        print(\"Colors are not produced because of missing color dict.\")\n",
    "        colors = None\n",
    "\n",
    "    return labels, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = Path(\n",
    "    \"/gpfs01/berens/user/rgonzalesmarquez/phd/iclr-dataset/results/variables/iclr26v1\"\n",
    ")\n",
    "\n",
    "pickle_in = open(\n",
    "    saving_path / \"dict_label_to_color.pkl\",\n",
    "    \"rb\",\n",
    ")\n",
    "dict_label_to_color = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 s, sys: 299 ms, total: 1.74 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels_iclr, colors_iclr = assign_labels_and_colors(\n",
    "    iclr.keywords.to_list(),\n",
    "    final_keywords_groups,\n",
    "    dict_keyword_to_label,\n",
    "    dict_label_to_color,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "np.save(variables_path / \"labels_iclr\", labels_iclr)\n",
    "np.save(variables_path / \"colors_iclr\", colors_iclr)\n",
    "\n",
    "f = open(variables_path / \"dict_label_to_color.pkl\", \"wb\")\n",
    "pickle.dump(dict_label_to_color, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of unlabeled papers:  45.38153328801918\n",
      "Number of unlabeled papers:  25371\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of unlabeled papers: \",\n",
    "    np.sum(labels_iclr == \"unlabeled\") / len(labels_iclr) * 100,\n",
    ")\n",
    "print(\n",
    "    \"Number of unlabeled papers: \",\n",
    "    np.sum(labels_iclr == \"unlabeled\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New 2026 classes\n",
      "Number of 3D scenes papers:  331\n",
      "Number of speech papers:  131\n",
      "Number of molecules papers:  137\n",
      "Number of PDEs papers:  291\n"
     ]
    }
   ],
   "source": [
    "print(\"New 2026 classes\")\n",
    "print(\n",
    "    \"Number of 3D scenes papers: \",\n",
    "    np.sum(labels_iclr == \"3D scenes\"),\n",
    ")\n",
    "print(\n",
    "    \"Number of speech papers: \",\n",
    "    np.sum(labels_iclr == \"speech\"),\n",
    ")\n",
    "print(\n",
    "    \"Number of molecules papers: \",\n",
    "    np.sum(labels_iclr == \"molecules\"),\n",
    ")\n",
    "print(\n",
    "    \"Number of PDEs papers: \",\n",
    "    np.sum(labels_iclr == \"PDEs\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers without any keywords:  3.8117554466425787\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Papers without any keywords: \",\n",
    "    np.sum([1 if elem == [] else 0 for elem in iclr.keywords])\n",
    "    / len(labels_iclr)\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column to dataframe and resave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td></td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td>transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td></td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         id                                              title  \\\n",
       "0  2017  B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1  2017  B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2  2017  B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3  2017  B16dGcqlx                    Third Person Imitation Learning   \n",
       "4  2017  B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A recent approach to few-shot classification c...   \n",
       "1  Machine comprehension of text is an important ...   \n",
       "2  Generative adversarial networks (GANs) provide...   \n",
       "3  Reinforcement learning (RL) makes it possible ...   \n",
       "4  We propose an extension to neural network lang...   \n",
       "\n",
       "                                          authors author_ids  \\\n",
       "0        Jake Snell, Kevin Swersky, Richard Zemel              \n",
       "1                       Shuohang Wang, Jing Jiang              \n",
       "2         Shakir Mohamed, Balaji Lakshminarayanan              \n",
       "3  Bradly C Stadie, Pieter Abbeel, Ilya Sutskever              \n",
       "4   Edouard Grave, Armand Joulin, Nicolas Usunier              \n",
       "\n",
       "                   decision     scores  \\\n",
       "0                    Reject  [6, 4, 5]   \n",
       "1           Accept (Poster)  [6, 6, 7]   \n",
       "2  Invite to Workshop Track  [8, 7, 6]   \n",
       "3           Accept (Poster)  [6, 5, 6]   \n",
       "4           Accept (Poster)  [7, 9, 5]   \n",
       "\n",
       "                                       keywords             labels  \n",
       "0            [deep learning, transfer learning]  transfer learning  \n",
       "1  [natural language processing, deep learning]    language models  \n",
       "2                       [unsupervised learning]          unlabeled  \n",
       "3                                            []          unlabeled  \n",
       "4                 [natural language processing]    language models  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr[\"labels\"] = labels_iclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55901</th>\n",
       "      <td>2026</td>\n",
       "      <td>zz3El6hqbs</td>\n",
       "      <td>Learning activation functions with PCA on a se...</td>\n",
       "      <td>This work explores a novel approach to learnin...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[deep neural networks, activation function lea...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55902</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzJTo7ujql</td>\n",
       "      <td>Phased DMD: Few-step Distribution Matching Dis...</td>\n",
       "      <td>Distribution Matching Distillation (DMD) disti...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[diffusion models, distribution matching, dist...</td>\n",
       "      <td>diffusion models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55903</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzTDulLys0</td>\n",
       "      <td>vAttention: Verified Sparse Attention via Samp...</td>\n",
       "      <td>State-of-the-art sparse attention methods for ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[sparse attention]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55904</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzTQISAGUp</td>\n",
       "      <td>Polychromic Objectives for Reinforcement Learning</td>\n",
       "      <td>Reinforcement learning fine-tuning (RLFT) is a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[reinforcement learning, exploration]</td>\n",
       "      <td>RL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55905</th>\n",
       "      <td>2026</td>\n",
       "      <td>zzo3Sy3NSX</td>\n",
       "      <td>Your Language Model Secretly Contains Personal...</td>\n",
       "      <td>Large Language Models (LLMs) demonstrate remar...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[large language models, persona modeling]</td>\n",
       "      <td>LLMs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year          id                                              title  \\\n",
       "55901  2026  zz3El6hqbs  Learning activation functions with PCA on a se...   \n",
       "55902  2026  zzJTo7ujql  Phased DMD: Few-step Distribution Matching Dis...   \n",
       "55903  2026  zzTDulLys0  vAttention: Verified Sparse Attention via Samp...   \n",
       "55904  2026  zzTQISAGUp  Polychromic Objectives for Reinforcement Learning   \n",
       "55905  2026  zzo3Sy3NSX  Your Language Model Secretly Contains Personal...   \n",
       "\n",
       "                                                abstract authors author_ids  \\\n",
       "55901  This work explores a novel approach to learnin...                      \n",
       "55902  Distribution Matching Distillation (DMD) disti...                      \n",
       "55903  State-of-the-art sparse attention methods for ...                      \n",
       "55904  Reinforcement learning fine-tuning (RLFT) is a...                      \n",
       "55905  Large Language Models (LLMs) demonstrate remar...                      \n",
       "\n",
       "      decision scores                                           keywords  \\\n",
       "55901              []  [deep neural networks, activation function lea...   \n",
       "55902              []  [diffusion models, distribution matching, dist...   \n",
       "55903              []                                 [sparse attention]   \n",
       "55904              []              [reinforcement learning, exploration]   \n",
       "55905              []          [large language models, persona modeling]   \n",
       "\n",
       "                 labels  \n",
       "55901         unlabeled  \n",
       "55902  diffusion models  \n",
       "55903         unlabeled  \n",
       "55904                RL  \n",
       "55905              LLMs  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4693073308745516"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((iclr.labels == \"unlabeled\") & (iclr.year == 2026)) / np.sum(\n",
    "    iclr.year == 2026\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "iclr.to_parquet(\n",
    "    data_path / \"iclr26v1.parquet\",\n",
    "    index=False,\n",
    "    engine=\"pyarrow\",\n",
    "    # engine=\"fastparquet\", # TODO: change engine to fastparquet once all scores are there\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
