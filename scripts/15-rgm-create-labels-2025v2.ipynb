{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import glasbey\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "from pathlib import Path\n",
    "import distro\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(line_length=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_path = Path(\"../results/variables/iclr25v2\")\n",
    "figures_path = Path(\"../results/figures\")\n",
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs01/berens/user/rgonzalesmarquez'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL FIX TO PATH ISSUE FROM VSCODE\n",
    "nb_path = Path(\"phd/iclr-dataset/scripts\")\n",
    "assert nb_path.exists(), \"The path does not exist\"\n",
    "\n",
    "variables_path = (nb_path / variables_path).resolve(strict=True)\n",
    "figures_path = (nb_path / figures_path).resolve(strict=True)\n",
    "data_path = (nb_path / data_path).resolve(strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs01/berens/user/rgonzalesmarquez/phd/iclr-dataset/results/variables/iclr25v2\n"
     ]
    }
   ],
   "source": [
    "print(variables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use((nb_path / Path(\"matplotlib_style.txt\")).resolve(strict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Rita Gonz치lez-M치rquez\n",
      "\n",
      "Last updated: 2025-11-17 11:00:08CET\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.4\n",
      "IPython version      : 8.31.0\n",
      "\n",
      "transformers: 4.45.2\n",
      "openTSNE    : 1.0.2\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 4.18.0-553.el8_10.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: rgonzalesmarquez_GPU0-llm_gber7\n",
      "\n",
      "distro         : 1.9.0\n",
      "pandas         : 2.2.3\n",
      "matplotlib     : 3.9.2\n",
      "jupyter_black  : 0.4.0\n",
      "numpy          : 1.26.4\n",
      "seaborn        : 0.13.2\n",
      "glasbey        : 0.2.1\n",
      "memory_profiler: 0.61.0\n",
      "\n",
      "Watermark: 2.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -a 'Rita Gonz치lez-M치rquez' -t -d -tz -u -v -iv -w -m -h -p transformers,openTSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "ICLR new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 183 ms, sys: 65 ms, total: 248 ms\n",
      "Wall time: 929 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iclr = pd.read_parquet(\n",
    "    data_path / \"iclr25v2.parquet\",\n",
    "    engine=\"fastparquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36108</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxg6601zoc</td>\n",
       "      <td>Re-Imagining Multimodal Instruction Tuning: A ...</td>\n",
       "      <td>Multimodal instruction tuning has proven to be...</td>\n",
       "      <td>Yiyang Liu, James Chenhao Liang, Ruixiang Tang...</td>\n",
       "      <td>~Yiyang_Liu3, ~James_Chenhao_Liang1, ~Ruixiang...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 6, 5]</td>\n",
       "      <td>[representation tuning, large multimodal model...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36109</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxqdVo9FjY</td>\n",
       "      <td>Generalization for Least Squares Regression wi...</td>\n",
       "      <td>Random matrix theory has proven to be a valuab...</td>\n",
       "      <td>Jiping Li, Rishi Sonthalia</td>\n",
       "      <td>~Jiping_Li1, ~Rishi_Sonthalia1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[5, 3, 5, 5, 6]</td>\n",
       "      <td>[generalization, random matrix theory, spiked ...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36110</th>\n",
       "      <td>2025</td>\n",
       "      <td>zyGrziIVdE</td>\n",
       "      <td>Exploration by Running Away from the Past</td>\n",
       "      <td>The ability to explore efficiently and effecti...</td>\n",
       "      <td>Paul-Antoine LE TOLGUENEC, Yann Besse, Florent...</td>\n",
       "      <td>~Paul-Antoine_LE_TOLGUENEC1, ~Yann_Besse2, ~Fl...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[3, 3, 5, 3]</td>\n",
       "      <td>[reinforcement learning, exploration, deep lea...</td>\n",
       "      <td>RL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36111</th>\n",
       "      <td>2025</td>\n",
       "      <td>zz9jAssrwL</td>\n",
       "      <td>Bayesian Policy Distillation via Offline RL fo...</td>\n",
       "      <td>High-performance deep reinforcement learning f...</td>\n",
       "      <td>Jangwon Kim, Yoonsu Jang, Jonghyeok Park, Yoon...</td>\n",
       "      <td>~Jangwon_Kim2, ~Yoonsu_Jang1, ~Jonghyeok_Park3...</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>[3, 3, 6]</td>\n",
       "      <td>[neural network compression, reinforcement lea...</td>\n",
       "      <td>RL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36112</th>\n",
       "      <td>2025</td>\n",
       "      <td>zzR1Uskhj0</td>\n",
       "      <td>High Probability Bounds for Cross-Learning Con...</td>\n",
       "      <td>Motivated by applications in online bidding an...</td>\n",
       "      <td>Ruiyuan Huang, Zengfeng Huang</td>\n",
       "      <td>~Ruiyuan_Huang1, ~Zengfeng_Huang1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[5, 5, 8, 6, 6]</td>\n",
       "      <td>[contextual bandits, cross-learning, high-prob...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year          id                                              title  \\\n",
       "36108  2025  zxg6601zoc  Re-Imagining Multimodal Instruction Tuning: A ...   \n",
       "36109  2025  zxqdVo9FjY  Generalization for Least Squares Regression wi...   \n",
       "36110  2025  zyGrziIVdE          Exploration by Running Away from the Past   \n",
       "36111  2025  zz9jAssrwL  Bayesian Policy Distillation via Offline RL fo...   \n",
       "36112  2025  zzR1Uskhj0  High Probability Bounds for Cross-Learning Con...   \n",
       "\n",
       "                                                abstract  \\\n",
       "36108  Multimodal instruction tuning has proven to be...   \n",
       "36109  Random matrix theory has proven to be a valuab...   \n",
       "36110  The ability to explore efficiently and effecti...   \n",
       "36111  High-performance deep reinforcement learning f...   \n",
       "36112  Motivated by applications in online bidding an...   \n",
       "\n",
       "                                                 authors  \\\n",
       "36108  Yiyang Liu, James Chenhao Liang, Ruixiang Tang...   \n",
       "36109                         Jiping Li, Rishi Sonthalia   \n",
       "36110  Paul-Antoine LE TOLGUENEC, Yann Besse, Florent...   \n",
       "36111  Jangwon Kim, Yoonsu Jang, Jonghyeok Park, Yoon...   \n",
       "36112                      Ruiyuan Huang, Zengfeng Huang   \n",
       "\n",
       "                                              author_ids         decision  \\\n",
       "36108  ~Yiyang_Liu3, ~James_Chenhao_Liang1, ~Ruixiang...  Accept (Poster)   \n",
       "36109                     ~Jiping_Li1, ~Rishi_Sonthalia1           Reject   \n",
       "36110  ~Paul-Antoine_LE_TOLGUENEC1, ~Yann_Besse2, ~Fl...           Reject   \n",
       "36111  ~Jangwon_Kim2, ~Yoonsu_Jang1, ~Jonghyeok_Park3...        Withdrawn   \n",
       "36112                  ~Ruiyuan_Huang1, ~Zengfeng_Huang1           Reject   \n",
       "\n",
       "                scores                                           keywords  \\\n",
       "36108     [6, 6, 6, 5]  [representation tuning, large multimodal model...   \n",
       "36109  [5, 3, 5, 5, 6]  [generalization, random matrix theory, spiked ...   \n",
       "36110     [3, 3, 5, 3]  [reinforcement learning, exploration, deep lea...   \n",
       "36111        [3, 3, 6]  [neural network compression, reinforcement lea...   \n",
       "36112  [5, 5, 8, 6, 6]  [contextual bandits, cross-learning, high-prob...   \n",
       "\n",
       "          labels  \n",
       "36108  unlabeled  \n",
       "36109  unlabeled  \n",
       "36110         RL  \n",
       "36111         RL  \n",
       "36112  unlabeled  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr[\"keywords\"] = iclr[\"keywords\"].apply(lambda x: [s.lower() for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36108</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxg6601zoc</td>\n",
       "      <td>Re-Imagining Multimodal Instruction Tuning: A ...</td>\n",
       "      <td>Multimodal instruction tuning has proven to be...</td>\n",
       "      <td>Yiyang Liu, James Chenhao Liang, Ruixiang Tang...</td>\n",
       "      <td>~Yiyang_Liu3, ~James_Chenhao_Liang1, ~Ruixiang...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 6, 5]</td>\n",
       "      <td>[representation tuning, large multimodal model...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36109</th>\n",
       "      <td>2025</td>\n",
       "      <td>zxqdVo9FjY</td>\n",
       "      <td>Generalization for Least Squares Regression wi...</td>\n",
       "      <td>Random matrix theory has proven to be a valuab...</td>\n",
       "      <td>Jiping Li, Rishi Sonthalia</td>\n",
       "      <td>~Jiping_Li1, ~Rishi_Sonthalia1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[5, 3, 5, 5, 6]</td>\n",
       "      <td>[generalization, random matrix theory, spiked ...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36110</th>\n",
       "      <td>2025</td>\n",
       "      <td>zyGrziIVdE</td>\n",
       "      <td>Exploration by Running Away from the Past</td>\n",
       "      <td>The ability to explore efficiently and effecti...</td>\n",
       "      <td>Paul-Antoine LE TOLGUENEC, Yann Besse, Florent...</td>\n",
       "      <td>~Paul-Antoine_LE_TOLGUENEC1, ~Yann_Besse2, ~Fl...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[3, 3, 5, 3]</td>\n",
       "      <td>[reinforcement learning, exploration, deep lea...</td>\n",
       "      <td>RL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36111</th>\n",
       "      <td>2025</td>\n",
       "      <td>zz9jAssrwL</td>\n",
       "      <td>Bayesian Policy Distillation via Offline RL fo...</td>\n",
       "      <td>High-performance deep reinforcement learning f...</td>\n",
       "      <td>Jangwon Kim, Yoonsu Jang, Jonghyeok Park, Yoon...</td>\n",
       "      <td>~Jangwon_Kim2, ~Yoonsu_Jang1, ~Jonghyeok_Park3...</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>[3, 3, 6]</td>\n",
       "      <td>[neural network compression, reinforcement lea...</td>\n",
       "      <td>RL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36112</th>\n",
       "      <td>2025</td>\n",
       "      <td>zzR1Uskhj0</td>\n",
       "      <td>High Probability Bounds for Cross-Learning Con...</td>\n",
       "      <td>Motivated by applications in online bidding an...</td>\n",
       "      <td>Ruiyuan Huang, Zengfeng Huang</td>\n",
       "      <td>~Ruiyuan_Huang1, ~Zengfeng_Huang1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>[5, 5, 8, 6, 6]</td>\n",
       "      <td>[contextual bandits, cross-learning, high-prob...</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year          id                                              title  \\\n",
       "36108  2025  zxg6601zoc  Re-Imagining Multimodal Instruction Tuning: A ...   \n",
       "36109  2025  zxqdVo9FjY  Generalization for Least Squares Regression wi...   \n",
       "36110  2025  zyGrziIVdE          Exploration by Running Away from the Past   \n",
       "36111  2025  zz9jAssrwL  Bayesian Policy Distillation via Offline RL fo...   \n",
       "36112  2025  zzR1Uskhj0  High Probability Bounds for Cross-Learning Con...   \n",
       "\n",
       "                                                abstract  \\\n",
       "36108  Multimodal instruction tuning has proven to be...   \n",
       "36109  Random matrix theory has proven to be a valuab...   \n",
       "36110  The ability to explore efficiently and effecti...   \n",
       "36111  High-performance deep reinforcement learning f...   \n",
       "36112  Motivated by applications in online bidding an...   \n",
       "\n",
       "                                                 authors  \\\n",
       "36108  Yiyang Liu, James Chenhao Liang, Ruixiang Tang...   \n",
       "36109                         Jiping Li, Rishi Sonthalia   \n",
       "36110  Paul-Antoine LE TOLGUENEC, Yann Besse, Florent...   \n",
       "36111  Jangwon Kim, Yoonsu Jang, Jonghyeok Park, Yoon...   \n",
       "36112                      Ruiyuan Huang, Zengfeng Huang   \n",
       "\n",
       "                                              author_ids         decision  \\\n",
       "36108  ~Yiyang_Liu3, ~James_Chenhao_Liang1, ~Ruixiang...  Accept (Poster)   \n",
       "36109                     ~Jiping_Li1, ~Rishi_Sonthalia1           Reject   \n",
       "36110  ~Paul-Antoine_LE_TOLGUENEC1, ~Yann_Besse2, ~Fl...           Reject   \n",
       "36111  ~Jangwon_Kim2, ~Yoonsu_Jang1, ~Jonghyeok_Park3...        Withdrawn   \n",
       "36112                  ~Ruiyuan_Huang1, ~Zengfeng_Huang1           Reject   \n",
       "\n",
       "                scores                                           keywords  \\\n",
       "36108     [6, 6, 6, 5]  [representation tuning, large multimodal model...   \n",
       "36109  [5, 3, 5, 5, 6]  [generalization, random matrix theory, spiked ...   \n",
       "36110     [3, 3, 5, 3]  [reinforcement learning, exploration, deep lea...   \n",
       "36111        [3, 3, 6]  [neural network compression, reinforcement lea...   \n",
       "36112  [5, 5, 8, 6, 6]  [contextual bandits, cross-learning, high-prob...   \n",
       "\n",
       "          labels  \n",
       "36108  unlabeled  \n",
       "36109  unlabeled  \n",
       "36110         RL  \n",
       "36111         RL  \n",
       "36112  unlabeled  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36113, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign new labels\n",
    "Labels are the same as for the 25v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists of keywords and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keyword_to_label_25 = {\n",
    "    ###### ADVERSARIAL\n",
    "    \"adversarial\": \"adversarial\",\n",
    "    \"adversarial attack\": \"adversarial\",\n",
    "    \"adversarial attacks\": \"adversarial\",\n",
    "    \"adversarial defense\": \"adversarial\",\n",
    "    \"adversarial examples\": \"adversarial\",\n",
    "    \"adversarial example\": \"adversarial\",  # NEW 2025\n",
    "    \"adversarial learning\": \"adversarial\",\n",
    "    \"adversarial machine learning\": \"adversarial\",\n",
    "    \"adversarial robustness\": \"adversarial\",\n",
    "    \"adversarial training\": \"adversarial\",\n",
    "    ###### TRANSFORMERS\n",
    "    \"attention\": \"transformers\",\n",
    "    \"attention mechanism\": \"transformers\",\n",
    "    \"transformer\": \"transformers\",\n",
    "    \"transformers\": \"transformers\",\n",
    "    \"self-attention\": \"transformers\",\n",
    "    ###### AUTOENCODERS\n",
    "    \"autoencoder\": \"autoencoders\",\n",
    "    \"autoencoders\": \"autoencoders\",\n",
    "    \"vae\": \"autoencoders\",\n",
    "    \"vaes\": \"autoencoders\",  # NEW 2025\n",
    "    \"variational autoencoder\": \"autoencoders\",\n",
    "    \"variational autoencoders\": \"autoencoders\",\n",
    "    ######\n",
    "    \"anomaly detection\": \"anomaly detection\",\n",
    "    ###### CAUSALITY\n",
    "    \"causal discovery\": \"causality\",\n",
    "    \"causal inference\": \"causality\",\n",
    "    \"causality\": \"causality\",\n",
    "    ######\n",
    "    \"clustering\": \"clustering\",\n",
    "    ###### COMPRESSION\n",
    "    \"compression\": \"compression\",\n",
    "    \"model compression\": \"compression\",\n",
    "    ######\n",
    "    \"object detection\": \"object detection\",\n",
    "    \"semantic segmentation\": \"object detection\",  # NEW 2025\n",
    "    # ######  -- MOVED TO SSL IN 2025\n",
    "    # \"contrastive learning\": \"contrastive learning\",\n",
    "    ###### CNNs\n",
    "    \"convolutional neural network\": \"CNNs\",\n",
    "    \"convolutional neural networks\": \"CNNs\",\n",
    "    \"cnn\": \"CNNs\",\n",
    "    \"cnns\": \"CNNs\",  # NEW 2025\n",
    "    ###### DIFFUSION MODELS\n",
    "    \"diffusion\": \"diffusion models\",\n",
    "    \"diffusion model\": \"diffusion models\",\n",
    "    \"diffusion models\": \"diffusion models\",\n",
    "    ###### EXPLAINABILITY\n",
    "    \"explainability\": \"explainability\",\n",
    "    \"explainable ai\": \"explainability\",\n",
    "    ######\n",
    "    \"interpretability\": \"interpretability\",\n",
    "    ######\n",
    "    \"fairness\": \"fairness\",\n",
    "    ######\n",
    "    \"federated learning\": \"federated learning\",\n",
    "    ###### GANs\n",
    "    \"generative adversarial network\": \"GANs\",\n",
    "    \"generative adversarial networks\": \"GANs\",\n",
    "    \"gan\": \"GANs\",\n",
    "    \"gans\": \"GANs\",\n",
    "    ###### GRAPHS\n",
    "    \"graph\": \"graphs\",\n",
    "    \"graphs\": \"graphs\",  # NEW 2025\n",
    "    \"graph neural network\": \"graphs\",\n",
    "    \"graph neural networks\": \"graphs\",\n",
    "    \"graph representation learning\": \"graphs\",\n",
    "    \"gnn\": \"graphs\",  # NEW 2025\n",
    "    \"gnns\": \"graphs\",\n",
    "    \"node classification\": \"graphs\",\n",
    "    ###### LLMs\n",
    "    \"llm\": \"LLMs\",\n",
    "    \"large language model\": \"LLMs\",\n",
    "    \"large language models\": \"LLMs\",\n",
    "    \"prompting\": \"LLMs\",\n",
    "    \"bert\": \"LLMs\",  # NEW 2025\n",
    "    \"llms\": \"LLMs\",  # NEW 2025\n",
    "    \"text generation\": \"LLMs\",  # NEW 2025\n",
    "    ######\n",
    "    \"knowledge distillation\": \"knowledge distillation\",\n",
    "    ###### LANGUAGE MODELS\n",
    "    \"natural language processing\": \"language models\",\n",
    "    \"nlp\": \"language models\",\n",
    "    \"language model\": \"language models\",\n",
    "    \"language models\": \"language models\",\n",
    "    \"language modeling\": \"language models\",\n",
    "    \"machine translation\": \"language models\",\n",
    "    \"question answering\": \"language models\",\n",
    "    \"reasoning\": \"language models\",\n",
    "    ###### META LEARNING\n",
    "    \"meta learning\": \"meta learning\",\n",
    "    \"meta-learning\": \"meta learning\",\n",
    "    ###### PRUNING\n",
    "    \"network pruning\": \"pruning\",\n",
    "    \"pruning\": \"pruning\",\n",
    "    ######\n",
    "    \"neural architecture search\": \"neural architecture search\",\n",
    "    ######\n",
    "    \"optimal transport\": \"optimal transport\",\n",
    "    ###### OPTIMIZATION\n",
    "    \"stochastic gradient descent\": \"optimization\",\n",
    "    \"stochastic optimization\": \"optimization\",\n",
    "    \"sgd\": \"optimization\",\n",
    "    \"optimization\": \"optimization\",\n",
    "    \"non-convex optimization\": \"optimization\",\n",
    "    \"convex optimization\": \"optimization\",\n",
    "    \"gradient descent\": \"optimization\",\n",
    "    \"combinatorial optimization\": \"optimization\",\n",
    "    \"bayesian optimization\": \"optimization\",\n",
    "    ###### OUT-OF-DISTRIBUTION\n",
    "    \"out-of-distribution\": \"out-of-distribution\",\n",
    "    \"out-of-distribution detection\": \"out-of-distribution\",\n",
    "    \"out-of-distribution generalization\": \"out-of-distribution\",\n",
    "    \"distribution shift\": \"out-of-distribution\",\n",
    "    ###### PRIVACY\n",
    "    \"differential privacy\": \"privacy\",\n",
    "    \"privacy\": \"privacy\",\n",
    "    ###### RNNs\n",
    "    \"rnn\": \"RNNs\",\n",
    "    \"rnns\": \"RNNs\",  # NEW 2025\n",
    "    \"recurrent neural network\": \"RNNs\",\n",
    "    \"recurrent neural networks\": \"RNNs\",\n",
    "    \"lstm\": \"RNNs\",\n",
    "    ###### REINFORCEMENT LEARNING\n",
    "    \"reinforcement learning\": \"RL\",\n",
    "    \"deep reinforcement learning\": \"RL\",\n",
    "    ######\n",
    "    \"active learning\": \"active learning\",\n",
    "    ######\n",
    "    \"model-based reinforcement learning\": \"model-based RL\",\n",
    "    ######\n",
    "    \"multi-agent reinforcement learning\": \"multi-agent RL\",\n",
    "    \"multi-agent\": \"multi-agent RL\",  # NEW 2025\n",
    "    ######\n",
    "    \"multi-task learning\": \"multi-task learning\",\n",
    "    ######\n",
    "    \"imitation learning\": \"imitation learning\",\n",
    "    ###### OFFLINE RL\n",
    "    \"offline reinforcement learning\": \"offline RL\",\n",
    "    \"offline rl\": \"offline RL\",\n",
    "    ###### CONTINUAL LEARNING\n",
    "    \"continual learning\": \"continual learning\",\n",
    "    \"lifelong learning\": \"continual learning\",\n",
    "    ######\n",
    "    \"in-context learning\": \"in-context learning\",\n",
    "    ######\n",
    "    \"few-shot learning\": \"few-shot learning\",\n",
    "    ######\n",
    "    \"robustness\": \"robustness\",\n",
    "    ###### SELF-SUPERVISED LEARNING\n",
    "    \"self-supervised learning\": \"self-supervised learning\",\n",
    "    \"contrastive learning\": \"self-supervised learning\",\n",
    "    ######\n",
    "    \"semi-supervised learning\": \"semi-supervised learning\",\n",
    "    ###### TIME SERIES\n",
    "    \"time series\": \"time series\",\n",
    "    \"time series forecasting\": \"time series\",\n",
    "    ###### TRANSFER LEARNING\n",
    "    \"transfer learning\": \"transfer learning\",\n",
    "    \"domain adaptation\": \"transfer learning\",\n",
    "    \"domain generalization\": \"transfer learning\",\n",
    "    ###### ViTs\n",
    "    \"vision transformer\": \"ViTs\",\n",
    "    \"vision transformers\": \"ViTs\",\n",
    "    ###### VISION-LANGUAGE MODELS\n",
    "    \"vision-language models\": \"vision-language models\",\n",
    "    \"vision-language model\": \"vision-language models\",  # NEW 2025\n",
    "    \"clip\": \"vision-language models\",\n",
    "    ###### ---------------------------- NEW 2025 --------------------------------\n",
    "    #### SAFETY\n",
    "    \"ai safety\": \"safety\",\n",
    "    \"safety\": \"safety\",\n",
    "    #### ALIGNMENT\n",
    "    \"alignment\": \"alignment\",\n",
    "    \"rlhf\": \"alignment\",\n",
    "    #####\n",
    "    \"autonomous driving\": \"autonomous driving\",\n",
    "    #### CODE GENERATION\n",
    "    \"code generation\": \"code generation\",\n",
    "    \"program synthesis\": \"code generation\",\n",
    "    #### KNOWLEDGE GRAPHS\n",
    "    \"knowledge graph\": \"knowledge graphs\",\n",
    "    \"knowledge graphs\": \"knowledge graphs\",\n",
    "    # ####\n",
    "    \"neuroscience\": \"neuroscience\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# keywords:  134\n",
      "# labels:  50\n"
     ]
    }
   ],
   "source": [
    "print(\"# keywords: \", len(np.unique(list(dict_keyword_to_label_25.keys()))))\n",
    "print(\"# labels: \", len(np.unique(list(dict_keyword_to_label_25.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025\n",
    "unique_keywords_25, counts_25 = np.unique(\n",
    "    np.hstack(iclr.keywords), return_counts=True\n",
    ")\n",
    "\n",
    "n = 200\n",
    "unique_keywords_25_sorted = unique_keywords_25[np.flip(np.argsort(counts_25))]\n",
    "counts_25_sorted = np.flip(np.sort(counts_25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keywords_frequencies_25 = dict(\n",
    "    zip(unique_keywords_25_sorted, counts_25_sorted)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('adversarial', 69),\n",
       "  ('adversarial attack', 158),\n",
       "  ('adversarial attacks', 155),\n",
       "  ('adversarial defense', 64),\n",
       "  ('adversarial examples', 211),\n",
       "  ('adversarial example', 34),\n",
       "  ('adversarial learning', 99),\n",
       "  ('adversarial machine learning', 65),\n",
       "  ('adversarial robustness', 303),\n",
       "  ('adversarial training', 252)],\n",
       " [('attention', 245),\n",
       "  ('attention mechanism', 74),\n",
       "  ('transformer', 511),\n",
       "  ('transformers', 414),\n",
       "  ('self-attention', 97)],\n",
       " [('autoencoder', 75),\n",
       "  ('autoencoders', 61),\n",
       "  ('vae', 84),\n",
       "  ('vaes', 10),\n",
       "  ('variational autoencoder', 109),\n",
       "  ('variational autoencoders', 90)],\n",
       " [('anomaly detection', 153)],\n",
       " [('causal discovery', 92), ('causal inference', 155), ('causality', 121)],\n",
       " [('clustering', 164)],\n",
       " [('compression', 166), ('model compression', 179)],\n",
       " [('object detection', 154), ('semantic segmentation', 113)],\n",
       " [('convolutional neural network', 82),\n",
       "  ('convolutional neural networks', 139),\n",
       "  ('cnn', 107),\n",
       "  ('cnns', 24)],\n",
       " [('diffusion', 175), ('diffusion model', 429), ('diffusion models', 635)],\n",
       " [('explainability', 198), ('explainable ai', 141)],\n",
       " [('interpretability', 572)],\n",
       " [('fairness', 270)],\n",
       " [('federated learning', 649)],\n",
       " [('generative adversarial network', 75),\n",
       "  ('generative adversarial networks', 197),\n",
       "  ('gan', 176),\n",
       "  ('gans', 98)],\n",
       " [('graph', 67),\n",
       "  ('graphs', 43),\n",
       "  ('graph neural network', 324),\n",
       "  ('graph neural networks', 763),\n",
       "  ('graph representation learning', 111),\n",
       "  ('gnn', 84),\n",
       "  ('gnns', 29),\n",
       "  ('node classification', 79)],\n",
       " [('llm', 430),\n",
       "  ('large language model', 664),\n",
       "  ('large language models', 1282),\n",
       "  ('prompting', 65),\n",
       "  ('bert', 85),\n",
       "  ('llms', 200),\n",
       "  ('text generation', 73)],\n",
       " [('knowledge distillation', 295)],\n",
       " [('natural language processing', 489),\n",
       "  ('nlp', 209),\n",
       "  ('language model', 169),\n",
       "  ('language models', 298),\n",
       "  ('language modeling', 106),\n",
       "  ('machine translation', 104),\n",
       "  ('question answering', 80),\n",
       "  ('reasoning', 207)],\n",
       " [('meta learning', 138), ('meta-learning', 331)],\n",
       " [('network pruning', 53), ('pruning', 172)],\n",
       " [('neural architecture search', 200)],\n",
       " [('optimal transport', 236)],\n",
       " [('stochastic gradient descent', 89),\n",
       "  ('stochastic optimization', 82),\n",
       "  ('sgd', 100),\n",
       "  ('optimization', 550),\n",
       "  ('non-convex optimization', 83),\n",
       "  ('convex optimization', 79),\n",
       "  ('gradient descent', 109),\n",
       "  ('combinatorial optimization', 102),\n",
       "  ('bayesian optimization', 93)],\n",
       " [('out-of-distribution', 72),\n",
       "  ('out-of-distribution detection', 131),\n",
       "  ('out-of-distribution generalization', 79),\n",
       "  ('distribution shift', 131)],\n",
       " [('differential privacy', 215), ('privacy', 161)],\n",
       " [('rnn', 76),\n",
       "  ('rnns', 30),\n",
       "  ('recurrent neural network', 54),\n",
       "  ('recurrent neural networks', 129),\n",
       "  ('lstm', 72)],\n",
       " [('reinforcement learning', 2076), ('deep reinforcement learning', 347)],\n",
       " [('active learning', 184)],\n",
       " [('model-based reinforcement learning', 132)],\n",
       " [('multi-agent reinforcement learning', 212), ('multi-agent', 70)],\n",
       " [('multi-task learning', 188)],\n",
       " [('imitation learning', 225)],\n",
       " [('offline reinforcement learning', 211), ('offline rl', 73)],\n",
       " [('continual learning', 460), ('lifelong learning', 101)],\n",
       " [('in-context learning', 245)],\n",
       " [('few-shot learning', 248)],\n",
       " [('robustness', 540)],\n",
       " [('self-supervised learning', 608), ('contrastive learning', 458)],\n",
       " [('semi-supervised learning', 274)],\n",
       " [('time series', 199), ('time series forecasting', 114)],\n",
       " [('transfer learning', 475),\n",
       "  ('domain adaptation', 228),\n",
       "  ('domain generalization', 151)],\n",
       " [('vision transformer', 117), ('vision transformers', 65)],\n",
       " [('vision-language models', 128),\n",
       "  ('vision-language model', 56),\n",
       "  ('clip', 126)],\n",
       " [('ai safety', 107), ('safety', 134)],\n",
       " [('alignment', 219), ('rlhf', 109)],\n",
       " [('autonomous driving', 109)],\n",
       " [('code generation', 96), ('program synthesis', 72)],\n",
       " [('knowledge graph', 71), ('knowledge graphs', 44)],\n",
       " [('neuroscience', 126)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_keywords_25 = [\n",
    "    dict_keywords_frequencies_25[key]\n",
    "    for key in dict_keyword_to_label_25.keys()\n",
    "]\n",
    "\n",
    "list_to_group = list(\n",
    "    zip(\n",
    "        dict_keyword_to_label_25.values(),\n",
    "        dict_keyword_to_label_25.keys(),\n",
    "        freqs_keywords_25,\n",
    "    )\n",
    ")\n",
    "key_func = lambda x: x[0]\n",
    "\n",
    "final_keywords_groups_25 = []\n",
    "for key, group in itertools.groupby(list_to_group, key_func):\n",
    "    final_keywords_groups_25.append([elem[1:] for elem in group])\n",
    "\n",
    "final_keywords_groups_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def assign_labels_and_colors(\n",
    "    data, keywords_and_freqs, dict_keyword_to_label, dict_color_legend=None\n",
    "):\n",
    "    \"\"\"Assign labels and colors from list with lists of keywords.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: list of lists, len (n_samples)\n",
    "        List with lists of keywords for every paper.\n",
    "    keywords_and_freqs: list of lists, len (n_labels)\n",
    "        List of keywords groups. Contains all keywords and frequencies, with sublists of subgroups of keywords.\n",
    "    dict_keyword_to_label: dict\n",
    "        Dictionary assigning to each keyword its label (e.g. to all keywords in same subgroup same label).\n",
    "    dict_color_legend: dict, len (n_labels)\n",
    "        Dictionary assigning to each label a color.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels: array, shape (n_samples,)\n",
    "        Label for each paper.\n",
    "    colors: array, shape (n_samples,)\n",
    "        Color for each paper.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare dict_freqs\n",
    "    dict_freqs = dict(list(itertools.chain.from_iterable(keywords_and_freqs)))\n",
    "    dict_freqs[\"unlabeled\"] = (\n",
    "        1e9  # assign very large value to unlabeled for argmax\n",
    "    )\n",
    "\n",
    "    # clean empty lists of keywords from the data\n",
    "    data_without_empty = [\n",
    "        [\"unlabeled\"] if elem == [] else elem for elem in data\n",
    "    ]\n",
    "\n",
    "    # choose keywords for each paper\n",
    "    chosen_keywords = []\n",
    "    for list_keywords in data_without_empty:\n",
    "        list_keywords_filtered = [\n",
    "            elem if elem in set(dict_freqs.keys()) else \"unlabeled\"\n",
    "            for elem in list_keywords\n",
    "        ]\n",
    "\n",
    "        freqs = np.vectorize(dict_freqs.get)(list_keywords_filtered)\n",
    "\n",
    "        chosen_keyword = list_keywords_filtered[np.argmin(freqs)]\n",
    "        chosen_keywords.append(chosen_keyword)\n",
    "\n",
    "    chosen_keywords = np.array(chosen_keywords)\n",
    "\n",
    "    # map chosen keywords to labels\n",
    "    dict_keyword_to_label[\"unlabeled\"] = \"unlabeled\"\n",
    "    labels = np.vectorize(dict_keyword_to_label.get)(chosen_keywords)\n",
    "\n",
    "    # colors\n",
    "    colors = np.vectorize(dict_color_legend.get)(labels)\n",
    "\n",
    "    return labels, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\n",
    "    \"/gpfs01/berens/user/rgonzalesmarquez/phd/iclr-dataset/results/variables/iclr25v1/dict_label_to_color.pkl\",\n",
    "    \"rb\",\n",
    ")\n",
    "dict_label_to_color_25 = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 923 ms, sys: 223 ms, total: 1.15 s\n",
      "Wall time: 940 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels_iclr, colors_iclr = assign_labels_and_colors(\n",
    "    iclr.keywords.to_list(),\n",
    "    final_keywords_groups_25,\n",
    "    dict_keyword_to_label_25,\n",
    "    dict_label_to_color_25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "np.save(variables_path / \"labels_iclr\", labels_iclr)\n",
    "np.save(variables_path / \"colors_iclr\", colors_iclr)\n",
    "\n",
    "f = open(variables_path / \"dict_label_to_color.pkl\", \"wb\")\n",
    "pickle.dump(dict_label_to_color_25, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of unlabeled papers:  45.62345969595437\n",
      "Number of unlabeled papers:  16476\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of unlabeled papers: \",\n",
    "    np.sum(labels_iclr == \"unlabeled\") / len(labels_iclr) * 100,\n",
    ")\n",
    "print(\n",
    "    \"Number of unlabeled papers: \",\n",
    "    np.sum(labels_iclr == \"unlabeled\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers without any keywords:  5.9009221056129375\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Papers without any keywords: \",\n",
    "    np.sum([1 if elem == [] else 0 for elem in iclr.keywords])\n",
    "    / len(labels_iclr)\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column to dataframe and resave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td></td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td></td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         id                                              title  \\\n",
       "0  2017  B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1  2017  B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2  2017  B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3  2017  B16dGcqlx                    Third Person Imitation Learning   \n",
       "4  2017  B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A recent approach to few-shot classification c...   \n",
       "1  Machine comprehension of text is an important ...   \n",
       "2  Generative adversarial networks (GANs) provide...   \n",
       "3  Reinforcement learning (RL) makes it possible ...   \n",
       "4  We propose an extension to neural network lang...   \n",
       "\n",
       "                                          authors author_ids  \\\n",
       "0        Jake Snell, Kevin Swersky, Richard Zemel              \n",
       "1                       Shuohang Wang, Jing Jiang              \n",
       "2         Shakir Mohamed, Balaji Lakshminarayanan              \n",
       "3  Bradly C Stadie, Pieter Abbeel, Ilya Sutskever              \n",
       "4   Edouard Grave, Armand Joulin, Nicolas Usunier              \n",
       "\n",
       "                   decision     scores  \\\n",
       "0                    Reject  [6, 4, 5]   \n",
       "1           Accept (Poster)  [6, 6, 7]   \n",
       "2  Invite to Workshop Track  [8, 7, 6]   \n",
       "3           Accept (Poster)  [6, 5, 6]   \n",
       "4           Accept (Poster)  [7, 9, 5]   \n",
       "\n",
       "                                       keywords labels  \n",
       "0            [deep learning, transfer learning]         \n",
       "1  [natural language processing, deep learning]         \n",
       "2                       [unsupervised learning]         \n",
       "3                                            []         \n",
       "4                 [natural language processing]         "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr[\"labels\"] = labels_iclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>decision</th>\n",
       "      <th>scores</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-Hhnslg</td>\n",
       "      <td>Prototypical Networks for Few-shot Learning</td>\n",
       "      <td>A recent approach to few-shot classification c...</td>\n",
       "      <td>Jake Snell, Kevin Swersky, Richard Zemel</td>\n",
       "      <td></td>\n",
       "      <td>Reject</td>\n",
       "      <td>[6, 4, 5]</td>\n",
       "      <td>[deep learning, transfer learning]</td>\n",
       "      <td>transfer learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>B1-q5Pqxl</td>\n",
       "      <td>Machine Comprehension Using Match-LSTM and Ans...</td>\n",
       "      <td>Machine comprehension of text is an important ...</td>\n",
       "      <td>Shuohang Wang, Jing Jiang</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 6, 7]</td>\n",
       "      <td>[natural language processing, deep learning]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16Jem9xe</td>\n",
       "      <td>Learning in Implicit Generative Models</td>\n",
       "      <td>Generative adversarial networks (GANs) provide...</td>\n",
       "      <td>Shakir Mohamed, Balaji Lakshminarayanan</td>\n",
       "      <td></td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>[8, 7, 6]</td>\n",
       "      <td>[unsupervised learning]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>B16dGcqlx</td>\n",
       "      <td>Third Person Imitation Learning</td>\n",
       "      <td>Reinforcement learning (RL) makes it possible ...</td>\n",
       "      <td>Bradly C Stadie, Pieter Abbeel, Ilya Sutskever</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>B184E5qee</td>\n",
       "      <td>Improving Neural Language Models with a Contin...</td>\n",
       "      <td>We propose an extension to neural network lang...</td>\n",
       "      <td>Edouard Grave, Armand Joulin, Nicolas Usunier</td>\n",
       "      <td></td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[7, 9, 5]</td>\n",
       "      <td>[natural language processing]</td>\n",
       "      <td>language models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year         id                                              title  \\\n",
       "0  2017  B1-Hhnslg        Prototypical Networks for Few-shot Learning   \n",
       "1  2017  B1-q5Pqxl  Machine Comprehension Using Match-LSTM and Ans...   \n",
       "2  2017  B16Jem9xe             Learning in Implicit Generative Models   \n",
       "3  2017  B16dGcqlx                    Third Person Imitation Learning   \n",
       "4  2017  B184E5qee  Improving Neural Language Models with a Contin...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A recent approach to few-shot classification c...   \n",
       "1  Machine comprehension of text is an important ...   \n",
       "2  Generative adversarial networks (GANs) provide...   \n",
       "3  Reinforcement learning (RL) makes it possible ...   \n",
       "4  We propose an extension to neural network lang...   \n",
       "\n",
       "                                          authors author_ids  \\\n",
       "0        Jake Snell, Kevin Swersky, Richard Zemel              \n",
       "1                       Shuohang Wang, Jing Jiang              \n",
       "2         Shakir Mohamed, Balaji Lakshminarayanan              \n",
       "3  Bradly C Stadie, Pieter Abbeel, Ilya Sutskever              \n",
       "4   Edouard Grave, Armand Joulin, Nicolas Usunier              \n",
       "\n",
       "                   decision     scores  \\\n",
       "0                    Reject  [6, 4, 5]   \n",
       "1           Accept (Poster)  [6, 6, 7]   \n",
       "2  Invite to Workshop Track  [8, 7, 6]   \n",
       "3           Accept (Poster)  [6, 5, 6]   \n",
       "4           Accept (Poster)  [7, 9, 5]   \n",
       "\n",
       "                                       keywords             labels  \n",
       "0            [deep learning, transfer learning]  transfer learning  \n",
       "1  [natural language processing, deep learning]    language models  \n",
       "2                       [unsupervised learning]          unlabeled  \n",
       "3                                            []          unlabeled  \n",
       "4                 [natural language processing]    language models  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4681471319557575"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((iclr.labels == \"unlabeled\") & (iclr.year == 2025)) / np.sum(\n",
    "    iclr.year == 2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "iclr.to_parquet(\n",
    "    data_path / \"iclr25v2.parquet\",\n",
    "    index=False,\n",
    "    engine=\"fastparquet\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
